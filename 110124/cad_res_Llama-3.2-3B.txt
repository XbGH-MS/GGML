llama.cpp (commit 668750357e66bfa3d1504b65699f5a0dfe3cb7cb)

Model tested: Llama-3.2-3B-Instruct-Q... from https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF
                   except for Q2_K comes from https://huggingface.co/second-state/Llama-3.2-3B-Instruct-GGUF

Command line: 
    > llama-cli.exe -m <model> -t <#-of-threads> -f long_prompt_2.txt -n 128 -co -s 42
    > llama-bench.exe -m <model> -p 128 -n 64 -t <#-of-threads>

|=====================================================================================|
|    Scenario    |    Model  | # threads | prompt-eval (t/s) | token-generation (t/s) |
|=====================================================================================|
|   llama-cli    |    Q2_K   |     2     |       13.76       |          9.64          |
|=====================================================================================|
|   llama-cli    |    Q2_K   |     4     |       31.23       |         22.44          |
|=====================================================================================|
|   llama-cli    |    Q2_K   |     8     |       65.14       |         38.88          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_4 |     2     |       44.85       |         16.52          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_4 |     4     |       99.06       |         32.72          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_4 |     8     |      186.58       |         39.14          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_8 |     2     |       58.17       |         17.05          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_8 |     4     |      111.86       |         31.65          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_8 |     8     |      216.93       |         39.80          |
|=====================================================================================|
|   llama-cli    |   Q4_0    |     2     |       26.25(*)    |         12.55(*)       |
|=====================================================================================|
|   llama-cli    |   Q4_0    |     4     |       59.95(*)    |         27.31(*)       |
|=====================================================================================|
|   llama-cli    |   Q4_0    |     8     |      121.34(*)    |         38.17(*)       |
|=====================================================================================|
|   llama-cli    |  Q4_K_M   |     2     |       18.58       |         11.75          |
|=====================================================================================|
|   llama-cli    |  Q4_K_M   |     4     |       43.61       |         26.18          |
|=====================================================================================|
|   llama-cli    |  Q4_K_M   |     8     |       88.53       |         36.36          |
|=====================================================================================|
|=====================================================================================|
|    Scenario    |    Model  | # threads |      pp128        |         tg64           |
|=====================================================================================|
|   llama-bench  |    Q2_K   |     2     |       15.03       |         11.12          |
|=====================================================================================|
|   llama-bench  |    Q2_K   |     4     |       34.02       |         25.48          |
|=====================================================================================|
|   llama-bench  |    Q2_K   |     8     |       60.89       |         45.73          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_4 |     2     |       59.14       |         21.64          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_4 |     4     |      130.58       |         40.46          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_4 |     8     |      250.30       |         46.51          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_8 |     2     |       70.63       |         18.94          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_8 |     4     |      163.67       |         39.44          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_8 |     8     |      298.65       |         46.39          |
|=====================================================================================|
|   llama-bench  |  Q4_0_8_8 |     2     |        5.80       |          4.75          |
|=====================================================================================|
|   llama-bench  |  Q4_0_8_8 |     4     |       11.94       |         10.42          |
|=====================================================================================|
|   llama-bench  |  Q4_0_8_8 |     8     |       23.33       |         17.35          |
|=====================================================================================|
|   llama-bench  |    Q4_0   |     2     |       30.04       |         15.68          |
|=====================================================================================|
|   llama-bench  |    Q4_0   |     4     |       69.84       |         33.27          |
|=====================================================================================|
|   llama-bench  |    Q4_0   |     8     |      143.34       |         47.85          |
|=====================================================================================|
|   llama-bench  |    Q4_K   |     2     |       21.35       |         14.81          |
|=====================================================================================|
|   llama-bench  |    Q4_K   |     4     |       47.56       |         31.90          |
|=====================================================================================|
|   llama-bench  |    Q4_K   |     8     |       98.40       |         44.11          |
|=====================================================================================|
(*) - output not valid: garbage strings instead of useful replies.
