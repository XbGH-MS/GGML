llama.cpp (commit 668750357e66bfa3d1504b65699f5a0dfe3cb7cb)

Model tested: https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF

Command line: 
    > llama-cli.exe -m <model> -t <#-of-threads> -f long_prompt_2.txt -n 128 -co -s 42
    > llama-bench.exe -m <model> -p 128 -n 64 -t <#-of-threads>

|=====================================================================================|
|    Scenario    |    Model  | # threads | prompt-eval (t/s) | token-generation (t/s) |
|=====================================================================================|
|   llama-cli    |    Q2_K   |     2     |       10.03       |          8.22          |
|=====================================================================================|
|   llama-cli    |    Q2_K   |     4     |       21.71       |         16.93          |
|=====================================================================================|
|   llama-cli    |    Q2_K   |     8     |       43.80       |         28.29          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_4 |     2     |       28.42       |         12.33          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_4 |     4     |       53.54       |         19.88          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_4 |     8     |       78.82       |         24.58          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_8 |     2     |       32.64       |         10.72          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_8 |     4     |       65.55       |         19.82          |
|=====================================================================================|
|   llama-cli    |  Q4_0_4_8 |     8     |      103.59       |         26.62          |
|=====================================================================================|
|   llama-cli    |   Q4_0    |     2     |       16.34       |          8.45          |
|=====================================================================================|
|   llama-cli    |   Q4_0    |     4     |       32.89       |         16.75          |
|=====================================================================================|
|   llama-cli    |   Q4_0    |     8     |       53.23       |         24.90          |
|=====================================================================================|
|   llama-cli    |  Q4_K_M   |     2     |       11.46       |          9.47          |
|=====================================================================================|
|   llama-cli    |  Q4_K_M   |     4     |       25.40       |         18.63          |
|=====================================================================================|
|   llama-cli    |  Q4_K_M   |     8     |       48.72       |         25.09          |
|=====================================================================================|
|=====================================================================================|
|    Scenario    |    Model  | # threads |      pp128        |         tg64           |
|=====================================================================================|
|   llama-bench  |    Q2_K   |     2     |       11.63       |         10.12          |
|=====================================================================================|
|   llama-bench  |    Q2_K   |     4     |       26.40       |         22.81          |
|=====================================================================================|
|   llama-bench  |    Q2_K   |     8     |       55.19       |         41.79          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_4 |     2     |       54.26       |         25.92          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_4 |     4     |      100.58       |         37.90          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_4 |     8     |      196.91       |         42.35          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_8 |     2     |       71.16       |         24.61          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_8 |     4     |      130.43       |         34.52          |
|=====================================================================================|
|   llama-bench  |  Q4_0_4_8 |     8     |      220.75       |         41.65          |
|=====================================================================================|
|   llama-bench  |    Q4_0   |     2     |       22.83       |         14.05          |
|=====================================================================================|
|   llama-bench  |    Q4_0   |     4     |       54.40       |         29.48          |
|=====================================================================================|
|   llama-bench  |    Q4_0   |     8     |      111.06       |         41.34          |
|=====================================================================================|
|   llama-bench  |   Q4_K_M  |     2     |       15.16       |         12.96          |
|=====================================================================================|
|   llama-bench  |   Q4_K_M  |     4     |       34.65       |         24.98          |
|=====================================================================================|
|   llama-bench  |   Q4_K_M  |     8     |       58.59       |         29.58          |
|=====================================================================================|
